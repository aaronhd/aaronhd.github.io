<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>1 on Yaoxian(Aaron)</title>
    <link>https://aaronhd.github.io/publication_types/1/</link>
    <description>Recent content in 1 on Yaoxian(Aaron)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 May 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://aaronhd.github.io/publication_types/1/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>2.5D Image based Robotic Grasping</title>
      <link>https://aaronhd.github.io/publication/anzcc2019/</link>
      <pubDate>Fri, 31 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaronhd.github.io/publication/anzcc2019/</guid>
      <description>We consider the problem of robotic grasping using depth + RGB information sampling from a real sensor. we design an encoder-decoder neural network to predict grasp policy in real time.</description>
    </item>
    
    <item>
      <title>UG-Net for Robotic Grasping using Only Depth Image</title>
      <link>https://aaronhd.github.io/publication/rcar2019/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://aaronhd.github.io/publication/rcar2019/</guid>
      <description>Our proposed U-Grasping fully convolutional neural network (UGNet) predicts the quality and the pose of grasp in pixel-wise.</description>
    </item>
    
  </channel>
</rss>